{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad344599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3526e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load BERT model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set max sequence length\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "class Model:\n",
    "    def load_model(self, load_path):\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "        checkpoint = torch.load(load_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        print(f'Model loaded from <== {load_path}')\n",
    "        return model\n",
    "\n",
    "    # predict sentence label , for model 1, (0 prediction refers to bot, 1 human), \n",
    "   \n",
    "  \n",
    "    def predict_hate(self, model, sentence):\n",
    "        tokens = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            max_length=MAX_SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        tokens = tokens.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens['input_ids'], token_type_ids=None, attention_mask=tokens['attention_mask'])\n",
    "        logits = outputs[0]\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "        return predicted.item()\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "    # Load Model and Evaluate, final out put would be (0 prediction refers to bot, 1 refers to human)\n",
    "        model1 = self.load_model('model_1.pt')\n",
    "\n",
    "        predictions=[]\n",
    "        for post in data:\n",
    "            result1=self.predict_hate(model1, post)\n",
    "            if result1==0:\n",
    "                predictions.append('bot')\n",
    "            else:\n",
    "\n",
    "                predictions.append('human')\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Instantiate the model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8e8b3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_38416\\1538130012.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'http\\S+', 'http')  # Remove URLs while preserving \"http\"\n",
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_38416\\1538130012.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'[^\\w\\s#@]', '')  # Remove punctuation except hashtags and mention\n",
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_38416\\1538130012.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'\\n', '')  # Remove newline characters\n",
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_38416\\1538130012.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'\\r', '')  # Remove line breaks\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== model_1.pt\n",
      "100 done!!\n",
      "200 done!!\n",
      "300 done!!\n",
      "400 done!!\n",
      "500 done!!\n",
      "600 done!!\n",
      "700 done!!\n",
      "800 done!!\n",
      "900 done!!\n",
      "1000 done!!\n",
      "1100 done!!\n",
      "1200 done!!\n",
      "1300 done!!\n",
      "1400 done!!\n",
      "1500 done!!\n",
      "1600 done!!\n",
      "1700 done!!\n",
      "1800 done!!\n",
      "1900 done!!\n",
      "2000 done!!\n",
      "2100 done!!\n",
      "2200 done!!\n",
      "2300 done!!\n",
      "2400 done!!\n",
      "2500 done!!\n",
      "2600 done!!\n",
      "2700 done!!\n",
      "2800 done!!\n",
      "2900 done!!\n",
      "3000 done!!\n",
      "3100 done!!\n",
      "3200 done!!\n",
      "3300 done!!\n",
      "3400 done!!\n",
      "3500 done!!\n",
      "3600 done!!\n",
      "3700 done!!\n",
      "3800 done!!\n",
      "3900 done!!\n",
      "4000 done!!\n",
      "4100 done!!\n",
      "4200 done!!\n",
      "4300 done!!\n",
      "4400 done!!\n",
      "4500 done!!\n",
      "4600 done!!\n",
      "4700 done!!\n",
      "4800 done!!\n",
      "4900 done!!\n",
      "5000 done!!\n"
     ]
    }
   ],
   "source": [
    "# Read your test data (in your data you dont need label column)\n",
    "test = pd.read_csv('gossipcop_fake_output_raw_id.csv')\n",
    "\n",
    "## Clean the text as like ths. its important it has to be like this\n",
    "test['full_text'] = test['full_text'].astype(str).str.lower()  # Convert text to lowercase\n",
    "test['full_text'] = test['full_text'].str.replace(r'http\\S+', 'http')  # Remove URLs while preserving \"http\"\n",
    "test['full_text'] = test['full_text'].str.replace(r'[^\\w\\s#@]', '')  # Remove punctuation except hashtags and mention\n",
    "test['full_text'] = test['full_text'].str.replace(r'\\n', '')  # Remove newline characters\n",
    "test['full_text'] = test['full_text'].str.replace(r'\\r', '')  # Remove line breaks\n",
    "test['full_text'] = test['full_text'].astype(str)\n",
    "\n",
    "model1 = model.load_model('model_1.pt')\n",
    "\n",
    "predictions=[]\n",
    "count = 0\n",
    "for post in test['full_text'][:5000]:\n",
    "    result1=model.predict_hate(model1, post)\n",
    "    if result1==0:\n",
    "        predictions.append('bot')\n",
    "    else:\n",
    "        predictions.append('human')\n",
    "    count = count + 1\n",
    "    if count%100 == 0:\n",
    "        print(str(count)+' done!!')\n",
    "if count%100 == 0:\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "#predictions = model.predict_proba(test['full_text'][:100]) # sent your test data for prediction\n",
    "\n",
    "# # you dont need this part since you dont have any label\n",
    "# accuracy = metrics.classification_report(test['label'][:100], predictions, digits=3)\n",
    "# print('Accuracy of model cascade: \\n')\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6feb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did miley cyrus and liam hemsworth secretly ge...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>did miley cyrus and liam hemsworth secretly ge...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon tea  daily link roundup did miley cy...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>did miley cyrus and liam hemsworth secretly ge...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>did miley cyrus and liam hemsworth secretly ge...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>them jenner girls are nasty 6s at best and cai...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>wait what  milk actually likes caitlyn jenner ...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>nasty looking caitlyn jenner shows off her leg...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>big lie</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>newest trump accuser perhaps hell label me jus...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  label\n",
       "0     did miley cyrus and liam hemsworth secretly ge...    bot\n",
       "1     did miley cyrus and liam hemsworth secretly ge...    bot\n",
       "2     afternoon tea  daily link roundup did miley cy...    bot\n",
       "3     did miley cyrus and liam hemsworth secretly ge...    bot\n",
       "4     did miley cyrus and liam hemsworth secretly ge...    bot\n",
       "...                                                 ...    ...\n",
       "4995  them jenner girls are nasty 6s at best and cai...  human\n",
       "4996  wait what  milk actually likes caitlyn jenner ...  human\n",
       "4997  nasty looking caitlyn jenner shows off her leg...  human\n",
       "4998                                            big lie    bot\n",
       "4999  newest trump accuser perhaps hell label me jus...    bot\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['Text'] = test['full_text'][:5000]\n",
    "result_df['label'] = predictions\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0570c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('gossipcop_fake_botometer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351451a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human    3593\n",
       "bot      1407\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
