{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effeb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3827c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load BERT model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set max sequence length\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "class Model:\n",
    "    def load_model(self, load_path):\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "        checkpoint = torch.load(load_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        print(f'Model loaded from <== {load_path}')\n",
    "        return model\n",
    "\n",
    "    # predict sentence label , for model 1, (0 prediction refers to bot, 1 human), \n",
    "   \n",
    "  \n",
    "    def predict_hate(self, model, sentence):\n",
    "        tokens = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            max_length=MAX_SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt')\n",
    "        tokens = tokens.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens['input_ids'], token_type_ids=None, attention_mask=tokens['attention_mask'])\n",
    "        logits = outputs[0]\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "        return predicted.item()\n",
    "\n",
    "    def predict_proba(self, data):\n",
    "    # Load Model and Evaluate, final out put would be (0 prediction refers to bot, 1 refers to human)\n",
    "        model1 = self.load_model('model_1.pt')\n",
    "\n",
    "        predictions=[]\n",
    "        for post in data:\n",
    "            result1=self.predict_hate(model1, post)\n",
    "            if result1==0:\n",
    "                predictions.append('bot')\n",
    "            else:\n",
    "\n",
    "                predictions.append('human')\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Instantiate the model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da712ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_42732\\2954933304.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'http\\S+', 'http')  # Remove URLs while preserving \"http\"\n",
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_42732\\2954933304.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'[^\\w\\s#@]', '')  # Remove punctuation except hashtags and mention\n",
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_42732\\2954933304.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'\\n', '')  # Remove newline characters\n",
      "C:\\Users\\Fuzel Shaik\\AppData\\Local\\Temp\\ipykernel_42732\\2954933304.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['full_text'] = test['full_text'].str.replace(r'\\r', '')  # Remove line breaks\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== model_1.pt\n",
      "100 done!!\n",
      "200 done!!\n",
      "300 done!!\n",
      "400 done!!\n",
      "500 done!!\n",
      "600 done!!\n",
      "700 done!!\n",
      "800 done!!\n",
      "900 done!!\n",
      "1000 done!!\n",
      "1100 done!!\n",
      "1200 done!!\n",
      "1300 done!!\n",
      "1400 done!!\n",
      "1500 done!!\n",
      "1600 done!!\n",
      "1700 done!!\n",
      "1800 done!!\n",
      "1900 done!!\n",
      "2000 done!!\n",
      "2100 done!!\n",
      "2200 done!!\n",
      "2300 done!!\n",
      "2400 done!!\n",
      "2500 done!!\n",
      "2600 done!!\n",
      "2700 done!!\n",
      "2800 done!!\n",
      "2900 done!!\n",
      "3000 done!!\n"
     ]
    }
   ],
   "source": [
    "# Read your test data (in your data you dont need label column)\n",
    "test = pd.read_csv('poitifact_real_output_raw_id.csv')\n",
    "\n",
    "## Clean the text as like ths. its important it has to be like this\n",
    "test['full_text'] = test['full_text'].astype(str).str.lower()  # Convert text to lowercase\n",
    "test['full_text'] = test['full_text'].str.replace(r'http\\S+', 'http')  # Remove URLs while preserving \"http\"\n",
    "test['full_text'] = test['full_text'].str.replace(r'[^\\w\\s#@]', '')  # Remove punctuation except hashtags and mention\n",
    "test['full_text'] = test['full_text'].str.replace(r'\\n', '')  # Remove newline characters\n",
    "test['full_text'] = test['full_text'].str.replace(r'\\r', '')  # Remove line breaks\n",
    "test['full_text'] = test['full_text'].astype(str)\n",
    "\n",
    "model1 = model.load_model('model_1.pt')\n",
    "\n",
    "predictions=[]\n",
    "count = 0\n",
    "for post in test['full_text'][:3000]:\n",
    "    result1=model.predict_hate(model1, post)\n",
    "    if result1==0:\n",
    "        predictions.append('bot')\n",
    "    else:\n",
    "        predictions.append('human')\n",
    "    count = count + 1\n",
    "    if count%100 == 0:\n",
    "        print(str(count)+' done!!')\n",
    "if count%100 == 0:\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "#predictions = model.predict_proba(test['full_text'][:100]) # sent your test data for prediction\n",
    "\n",
    "# # you dont need this part since you dont have any label\n",
    "# accuracy = metrics.classification_report(test['label'][:100], predictions, digits=3)\n",
    "# print('Accuracy of model cascade: \\n')\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf73436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small business owners join the national federa...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nearly a third of main street businesses say i...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hr704 new commemorating the 75th anniversary o...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a record number of small business owners are s...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the state director of the national federation ...</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>national federation of independent business re...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>do you know about section 179 heres an infogra...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>in 2012 saturday shoppers spent an estimated 5...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>just in chief justice john roberts issues rare...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>sorry chief justice john roberts but you do in...</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  label\n",
       "0     small business owners join the national federa...    bot\n",
       "1     nearly a third of main street businesses say i...  human\n",
       "2     hr704 new commemorating the 75th anniversary o...    bot\n",
       "3     a record number of small business owners are s...  human\n",
       "4     the state director of the national federation ...    bot\n",
       "...                                                 ...    ...\n",
       "2995  national federation of independent business re...  human\n",
       "2996  do you know about section 179 heres an infogra...  human\n",
       "2997  in 2012 saturday shoppers spent an estimated 5...  human\n",
       "2998  just in chief justice john roberts issues rare...  human\n",
       "2999  sorry chief justice john roberts but you do in...  human\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['Text'] = test['full_text'][:3000]\n",
    "result_df['label'] = predictions\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e93e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('poitifact_real_botometer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da11f384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human    1947\n",
       "bot      1053\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
